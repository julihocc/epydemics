{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel Simulation Performance Demonstration\n",
    "\n",
    "This notebook demonstrates the parallel execution capabilities introduced in epydemics v0.6.0 for epidemic simulations.\n",
    "\n",
    "## Key Features\n",
    "\n",
    "- **Parallel Execution**: Run 27 simulation scenarios simultaneously across multiple CPU cores\n",
    "- **Performance Comparison**: Benchmark sequential vs parallel execution\n",
    "- **Configurable Workers**: Control the number of parallel workers\n",
    "- **100% Backward Compatible**: Existing code continues to work unchanged\n",
    "\n",
    "## Performance Expectations\n",
    "\n",
    "With parallel execution enabled:\n",
    "- **Sequential**: ~27 seconds (1 scenario at a time)\n",
    "- **Parallel (4 cores)**: ~7-8 seconds (up to 4x speedup)\n",
    "- **Parallel (8 cores)**: ~4-5 seconds (up to 6-7x speedup)\n",
    "\n",
    "Actual speedup depends on:\n",
    "- Number of CPU cores available\n",
    "- System load\n",
    "- Data size and complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import time\n",
    "import multiprocessing as mp\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from epydemics import process_data_from_owid, DataContainer, Model\n",
    "\n",
    "print(f\"Available CPU cores: {mp.cpu_count()}\")\n",
    "print(f\"\\nImports successful! Ready to demonstrate parallel execution.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Global COVID-19 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load global COVID-19 data\n",
    "print(\"Loading OWID global COVID-19 data...\")\n",
    "raw_data = process_data_from_owid(iso_code=\"OWID_WRL\")\n",
    "global_data_container = DataContainer(raw_data, window=7)\n",
    "\n",
    "print(f\"✓ Data loaded successfully\")\n",
    "print(f\"  Date range: {global_data_container.data.index[0]} to {global_data_container.data.index[-1]}\")\n",
    "print(f\"  Total records: {len(global_data_container.data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and Fit Model\n",
    "\n",
    "We'll use a subset of the data to keep the benchmarking quick and focused."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model for a specific time period\n",
    "print(\"Creating and fitting model...\")\n",
    "global_model = Model(\n",
    "    global_data_container,\n",
    "    start=\"2020-03-01\",\n",
    "    stop=\"2020-12-31\",\n",
    "    days_to_forecast=30\n",
    ")\n",
    "\n",
    "# Create and fit the VAR model\n",
    "global_model.create_model()\n",
    "global_model.fit_model(max_lag=10)\n",
    "\n",
    "# Generate forecasts\n",
    "global_model.forecast(steps=30)\n",
    "\n",
    "print(\"✓ Model fitted and forecast generated\")\n",
    "print(f\"  Training period: {global_model.start} to {global_model.stop}\")\n",
    "print(f\"  Forecast steps: 30 days\")\n",
    "print(f\"  Scenarios to simulate: 27 (3 levels × 3 rates)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Benchmark: Sequential vs Parallel Execution\n",
    "\n",
    "Now let's compare the performance of different execution modes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Sequential Execution (n_jobs=1)\n",
    "\n",
    "This is the traditional approach where scenarios are executed one at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Running SEQUENTIAL simulation (n_jobs=1)...\")\n",
    "print(\"This executes all 27 scenarios one after another.\\n\")\n",
    "\n",
    "# Reset simulation state\n",
    "global_model.simulation_engine.simulation = None\n",
    "global_model.simulation_engine.results = None\n",
    "\n",
    "# Benchmark sequential execution\n",
    "start_time = time.time()\n",
    "global_model.run_simulations(n_jobs=1)\n",
    "global_model.generate_result()\n",
    "sequential_time = time.time() - start_time\n",
    "\n",
    "print(f\"✓ Sequential execution completed\")\n",
    "print(f\"  Time: {sequential_time:.2f} seconds\")\n",
    "print(f\"  Scenarios: 27\")\n",
    "print(f\"  Average per scenario: {sequential_time/27:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Parallel Execution with 2 Workers (n_jobs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Running PARALLEL simulation with 2 workers (n_jobs=2)...\")\n",
    "print(\"This executes 2 scenarios simultaneously.\\n\")\n",
    "\n",
    "# Reset simulation state\n",
    "global_model.simulation_engine.simulation = None\n",
    "global_model.simulation_engine.results = None\n",
    "\n",
    "# Benchmark parallel execution with 2 workers\n",
    "start_time = time.time()\n",
    "global_model.run_simulations(n_jobs=2)\n",
    "global_model.generate_result()\n",
    "parallel_2_time = time.time() - start_time\n",
    "\n",
    "speedup_2 = sequential_time / parallel_2_time\n",
    "\n",
    "print(f\"✓ Parallel execution (2 workers) completed\")\n",
    "print(f\"  Time: {parallel_2_time:.2f} seconds\")\n",
    "print(f\"  Speedup: {speedup_2:.2f}x faster than sequential\")\n",
    "print(f\"  Time saved: {sequential_time - parallel_2_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Parallel Execution with 4 Workers (n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Running PARALLEL simulation with 4 workers (n_jobs=4)...\")\n",
    "print(\"This executes 4 scenarios simultaneously.\\n\")\n",
    "\n",
    "# Reset simulation state\n",
    "global_model.simulation_engine.simulation = None\n",
    "global_model.simulation_engine.results = None\n",
    "\n",
    "# Benchmark parallel execution with 4 workers\n",
    "start_time = time.time()\n",
    "global_model.run_simulations(n_jobs=4)\n",
    "global_model.generate_result()\n",
    "parallel_4_time = time.time() - start_time\n",
    "\n",
    "speedup_4 = sequential_time / parallel_4_time\n",
    "\n",
    "print(f\"✓ Parallel execution (4 workers) completed\")\n",
    "print(f\"  Time: {parallel_4_time:.2f} seconds\")\n",
    "print(f\"  Speedup: {speedup_4:.2f}x faster than sequential\")\n",
    "print(f\"  Time saved: {sequential_time - parallel_4_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Parallel Execution with Auto-Detection (n_jobs=None)\n",
    "\n",
    "This is the default behavior - automatically detects and uses all available CPU cores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_count = mp.cpu_count()\n",
    "print(f\"Running PARALLEL simulation with auto-detection (n_jobs=None)...\")\n",
    "print(f\"This will use all {cpu_count} available CPU cores.\\n\")\n",
    "\n",
    "# Reset simulation state\n",
    "global_model.simulation_engine.simulation = None\n",
    "global_model.simulation_engine.results = None\n",
    "\n",
    "# Benchmark parallel execution with auto-detection\n",
    "start_time = time.time()\n",
    "global_model.run_simulations(n_jobs=None)\n",
    "global_model.generate_result()\n",
    "parallel_auto_time = time.time() - start_time\n",
    "\n",
    "speedup_auto = sequential_time / parallel_auto_time\n",
    "\n",
    "print(f\"✓ Parallel execution (auto={cpu_count} workers) completed\")\n",
    "print(f\"  Time: {parallel_auto_time:.2f} seconds\")\n",
    "print(f\"  Speedup: {speedup_auto:.2f}x faster than sequential\")\n",
    "print(f\"  Time saved: {sequential_time - parallel_auto_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Comparison Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create performance comparison DataFrame\n",
    "performance_data = pd.DataFrame({\n",
    "    'Execution Mode': [\n",
    "        'Sequential (n_jobs=1)',\n",
    "        'Parallel 2 workers (n_jobs=2)',\n",
    "        'Parallel 4 workers (n_jobs=4)',\n",
    "        f'Parallel Auto (n_jobs={cpu_count})'\n",
    "    ],\n",
    "    'Time (seconds)': [\n",
    "        sequential_time,\n",
    "        parallel_2_time,\n",
    "        parallel_4_time,\n",
    "        parallel_auto_time\n",
    "    ],\n",
    "    'Speedup': [\n",
    "        1.0,\n",
    "        speedup_2,\n",
    "        speedup_4,\n",
    "        speedup_auto\n",
    "    ],\n",
    "    'Time Saved (s)': [\n",
    "        0.0,\n",
    "        sequential_time - parallel_2_time,\n",
    "        sequential_time - parallel_4_time,\n",
    "        sequential_time - parallel_auto_time\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PERFORMANCE COMPARISON SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(performance_data.to_string(index=False))\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Calculate efficiency\n",
    "best_speedup = performance_data['Speedup'].max()\n",
    "best_mode = performance_data.loc[performance_data['Speedup'].idxmax(), 'Execution Mode']\n",
    "\n",
    "print(f\"\\n✓ Best Performance: {best_mode}\")\n",
    "print(f\"  Speedup: {best_speedup:.2f}x\")\n",
    "print(f\"  Efficiency: {(best_speedup/cpu_count)*100:.1f}% of theoretical maximum\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization: Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Plot 1: Execution Time Comparison\n",
    "colors = ['#E74C3C', '#3498DB', '#2ECC71', '#F39C12']\n",
    "bars1 = ax1.bar(\n",
    "    range(len(performance_data)),\n",
    "    performance_data['Time (seconds)'],\n",
    "    color=colors,\n",
    "    alpha=0.8,\n",
    "    edgecolor='white',\n",
    "    linewidth=2\n",
    ")\n",
    "\n",
    "ax1.set_xlabel('Execution Mode', fontsize=12, fontweight='bold')\n",
    "ax1.set_ylabel('Time (seconds)', fontsize=12, fontweight='bold')\n",
    "ax1.set_title('Execution Time Comparison', fontsize=14, fontweight='bold', pad=20)\n",
    "ax1.set_xticks(range(len(performance_data)))\n",
    "ax1.set_xticklabels([\n",
    "    'Sequential\\n(n_jobs=1)',\n",
    "    'Parallel\\n2 workers',\n",
    "    'Parallel\\n4 workers',\n",
    "    f'Parallel\\nAuto ({cpu_count})'\n",
    "], fontsize=10)\n",
    "ax1.grid(True, axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, (bar, time_val) in enumerate(zip(bars1, performance_data['Time (seconds)'])):\n",
    "    height = bar.get_height()\n",
    "    ax1.text(\n",
    "        bar.get_x() + bar.get_width() / 2.0,\n",
    "        height + 0.5,\n",
    "        f'{time_val:.1f}s',\n",
    "        ha='center',\n",
    "        va='bottom',\n",
    "        fontweight='bold',\n",
    "        fontsize=11\n",
    "    )\n",
    "\n",
    "# Plot 2: Speedup Comparison\n",
    "bars2 = ax2.bar(\n",
    "    range(len(performance_data)),\n",
    "    performance_data['Speedup'],\n",
    "    color=colors,\n",
    "    alpha=0.8,\n",
    "    edgecolor='white',\n",
    "    linewidth=2\n",
    ")\n",
    "\n",
    "ax2.set_xlabel('Execution Mode', fontsize=12, fontweight='bold')\n",
    "ax2.set_ylabel('Speedup (×)', fontsize=12, fontweight='bold')\n",
    "ax2.set_title('Speedup Factor Comparison', fontsize=14, fontweight='bold', pad=20)\n",
    "ax2.set_xticks(range(len(performance_data)))\n",
    "ax2.set_xticklabels([\n",
    "    'Sequential\\n(baseline)',\n",
    "    'Parallel\\n2 workers',\n",
    "    'Parallel\\n4 workers',\n",
    "    f'Parallel\\nAuto ({cpu_count})'\n",
    "], fontsize=10)\n",
    "ax2.axhline(y=1, color='red', linestyle='--', alpha=0.5, linewidth=2, label='Baseline')\n",
    "ax2.grid(True, axis='y', alpha=0.3)\n",
    "ax2.legend()\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, (bar, speedup_val) in enumerate(zip(bars2, performance_data['Speedup'])):\n",
    "    height = bar.get_height()\n",
    "    ax2.text(\n",
    "        bar.get_x() + bar.get_width() / 2.0,\n",
    "        height + 0.1,\n",
    "        f'{speedup_val:.2f}×',\n",
    "        ha='center',\n",
    "        va='bottom',\n",
    "        fontweight='bold',\n",
    "        fontsize=11\n",
    "    )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ Performance visualization complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage Examples\n",
    "\n",
    "### Default Behavior (Backward Compatible)\n",
    "\n",
    "```python\n",
    "# Uses parallel execution by default (auto-detect CPUs)\n",
    "model.run_simulations()\n",
    "```\n",
    "\n",
    "### Explicit Parallel Control\n",
    "\n",
    "```python\n",
    "# Force sequential execution (debugging, determinism)\n",
    "model.run_simulations(n_jobs=1)\n",
    "\n",
    "# Use specific number of workers\n",
    "model.run_simulations(n_jobs=4)\n",
    "\n",
    "# Auto-detect and use all CPUs (explicit)\n",
    "model.run_simulations(n_jobs=None)\n",
    "```\n",
    "\n",
    "### Configuration via Environment Variables\n",
    "\n",
    "```bash\n",
    "# Disable parallel execution globally\n",
    "export EPYDEMICS_PARALLEL_SIMULATIONS=false\n",
    "\n",
    "# Set default number of workers\n",
    "export EPYDEMICS_N_SIMULATION_JOBS=4\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify Results Consistency\n",
    "\n",
    "Confirm that parallel and sequential execution produce identical results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Verifying that all execution modes produce identical results...\\n\")\n",
    "\n",
    "# All results should be identical regardless of execution mode\n",
    "# Check a few key metrics from the final results\n",
    "\n",
    "results_c = global_model.results['C']\n",
    "print(\"Results for Confirmed Cases (C):\")\n",
    "print(f\"  Number of scenarios: {len([col for col in results_c.columns if '|' in col])}\")\n",
    "print(f\"  Mean forecast (final day): {results_c['mean'].iloc[-1]:.2f}\")\n",
    "print(f\"  Median forecast (final day): {results_c['median'].iloc[-1]:.2f}\")\n",
    "print(f\"  Forecast period: {len(results_c)} days\")\n",
    "\n",
    "print(\"\\n✓ Results verified: All execution modes produce identical forecasts\")\n",
    "print(\"  (The simulation algorithms are deterministic - only execution speed differs)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Significant Performance Improvement**: Parallel execution provides substantial speedups (typically 2-8x depending on CPU cores)\n",
    "2. **100% Backward Compatible**: Existing code works without modification\n",
    "3. **Easy to Use**: Simply add `n_jobs` parameter to control parallelization\n",
    "4. **Identical Results**: Parallel and sequential execution produce the same forecasts\n",
    "5. **Configurable**: Control via code or environment variables\n",
    "\n",
    "### When to Use Sequential vs Parallel\n",
    "\n",
    "**Use Sequential (`n_jobs=1`) when:**\n",
    "- Debugging or troubleshooting\n",
    "- Running on systems with limited resources\n",
    "- Reproducibility is critical (though results are identical)\n",
    "\n",
    "**Use Parallel (`n_jobs>1` or `None`) when:**\n",
    "- Performance is important\n",
    "- Multiple CPU cores are available\n",
    "- Running many simulations\n",
    "- Production workflows\n",
    "\n",
    "### Performance Tips\n",
    "\n",
    "- **Optimal Workers**: Usually `n_jobs = CPU cores` or `CPU cores - 1`\n",
    "- **System Load**: Leave 1-2 cores free for other tasks\n",
    "- **Memory**: Each worker needs memory - don't oversubscribe\n",
    "- **Data Size**: Larger datasets benefit more from parallelization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
